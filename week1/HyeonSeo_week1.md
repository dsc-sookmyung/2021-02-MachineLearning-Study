# Week1 머신러닝 스터디 정리
***
##딥러닝 소개
---

주택가격 예측 예제로 6개의 주택 데이터가 있다고 했을 때 주택의 크기를 바탕으로 주택의 가격을 예측하는 함수를 만든다
-> 하나의 간단한 신경망
**size X -> 뉴런 -> price Y

여기서 뉴런이 하는 일
: 주택의 크기를 입력받아 선형함수를 계산하고, 결과값과 0 중 더 큰 값을 주택의 가격으로 예측한다

뉴런 하나를 하나의 레고블록으로 볼 수 있다
-> 더 많은 레고블록을 쌓음으로 더 큰 신경망을 만들 수 있다

주택 가격 에측으로
**입력값 X**              ->         **은닉유닛**        ->           **결과값 Y**
집의 크기(size)                   가족의 크기(family size)  
침실의 개수(bedrooms)                                              집의 가격
우편번호(zipcode)                 걸어다니기 좋은 동네
동네의 부(wealth)                 혹은 명문 학교의 여부    

신경망 : 입력값을 바탕으로 여러개의 은닉유닛을 가지고, 이를 종합하여 결과값을 알아낸다
         은닉 유닛은 4개의 입려을 다 받는다. -> 입력값(X)와 서로 긴밀하게 연결되어 있따고 할 수 있다
         충분한 양의 XY훈련예제를 준다면 X를 Y로 연결하는 함수가 뛰어나질 것이다.

신경망을 통해 만들어진 경제적 가치들은 머신러닝의 한 종류인 지도학습에 의해 만들어졌다.
**지도학습 : 입력 X와 출력 Y에 매핑되는 함수를 학습하려 한다**
ex) 광고 정보와 유저 정보를 바탕으로 온라인 광고를 수행       ->      표준 신경망 구조
    서로 다른 이미지들을 태깅                                ->      표준 신경망 구조
    음성인식                                                 ->      CNN(합성곱 신경망)
    기계번역                                                 ->      RNN(순환신경망)
    자연어 처리                                              ->      RNN
    앞 차에 대한 정보와 레이저 정보를 통한 자율주행           ->      더 복잡한 하이브리드
   
적절한 XY를 통해 지도학습, 서로 다른 적절한 응용분야에 적용


데이터의 종류
**구조적 데이터 : 데이터베이스로 표현된 데이터**
                    ex) 주택가격(크기, 침실의 수 등), 광고 클릭(사용자 나이, 광고에 대한 정보 등)
**비구조적 데이터 : 음성파일, 이미지, 텍스트 등 픽셀값이나 단어로 이루어진 데이터**
-> 구조적 데이터보다 비구조적 데이터가 컴퓨터가 작업하기 훨씬 어렵다
-> 딥러닝 덕분에 비구조적 데이터 분석이 많이 발전했다
그러나 발생하는 경제적인 이익은 보통 구조적 데이터에서 많이 발생한다. 방대한 데이터를 기반으로 정확한 예측을 하는 경우 딥러닝이 유리하다

신경망과 관련한 기술적 아이디어는 오래 전부터 존재했다
딥러닝이 급부상한 이유
  데이터의 양이 많아질수록 전통적인 학습 알고리즘의 성능은 정체기에 이른다
  20년간 사회가 변화하면서 꽤 많은 데이터를 가지게 되었는데, 전통적인 학습 알고리즘이 효과적으로 처리할 수 있는 양 이상의 데이터가 쌓이게 되었다
  많지 않은 데이터를 처리하는 부분에서 전통적인 학습 알고리즘은 딥러닝 학습 알고리즘보다 더 효과적일 수 있으나
  데이터가 많아질수록 신경망이 큰 딥러닝 학습 알고리즘과 전통적인 학습 알고리즘의 성능 차이가 벌어지게 되었다
  
**딥러닝의 아주 좋은 성능을 위해 필요한 두가지 요소**
1. 많은 양의 데이터를 이용하기 위한 충분히 큰 신경망
2. 많은 데이터
신경망의 크기 = 많은 은닉유닛, 많은 연결, 많은 파라미터, 데이터의 규모
성능을 올릴 때 가장 신뢰할 수 있는 방법 : 더 큰 신경 훈련망 또는 더 많은 데이터

데이터의 규모가 딥러닝을 부상하게 만들었다

딥러닝의 발전에는 방대한 양의 데이터, 컴퓨터의 빠른 계산능력, 그리고 알고리즘이 뒷받침한다
초창기 딥러닝의 문제는 데이터와 계산의 규모에 있었다
  기존의 시그모이드 함수는 양 끝단에서 미분값이 0과 가까워질수록 학습이 느려진다.
  이를 ReLu함수를 이용하는 알고리즘으로 변화시키자 입력값이 양수인경우, 경사가 모두 1로 같고, 경사가 서서히 0으로 수렴할 확률이 줄어든다
  즉, ReLu함수가 계산능력을 더 빠르게 만들었다
  이는 빠른 계산능력에 영향을 미쳤다
  빠른 계산이 중요한 이유는 많은 경우 신경망을 학습시키는 과정이 반복적이기 때문이다
  **신경망을 학습시키는 과정 : 아이디어 -> 코드작성 -> 실험 -> 결과 -> 신경망 수정 -> 반복**
  계산이 오래걸리면 위 사이클이 도는 시간도 오래걸리고, 결국 생산생에도 영향을 미친다
  빠른 계산시간은 실험의 결과를 얻는 시간을 빠르게 만들었고, 이는 신경망을 사용하는 사람과 딥러닝 연구자들에게 아이디어를 더 빨리 연구할 수 있도록 도움을 주었다





밑줄 : u <u>밑줄</u>
이텔릭체는 *별표*또는 _언더바_
두껍게는 **별표두개**또는 __언더바두개__
취소선은 ~~물결두개~~
목록
1. 순서존재
2. 순서
  -순서없음 마이너스
  *별
  +더하기
  
수평선 
---
마이너스3개
***
별 3개
___
언더바3개
줄바꿈 띄어쓰기 2개 또는 <br태그

# 딥러닝 소개

## **딥러닝이란?**

신경망(Neural Network)을 학습시키는 것

## **신경망은 무엇인가?**

- 신경망은 **입력(x)과 출력(y)을 매칭해주는 함수**를 찾는 과정
- 충분한 데이터가 주어지면 더 잘 알아낼 수 있음
- 해당 뉴런에 관계없는 입력값이라도 입력으로 넣어야 함.
관계 여부는 신경망이 학습하면서 알아서 조절해 감!
    
    <img width="500" alt="스크린샷_2021-09-28_오후_5 51 18" src="https://user-images.githubusercontent.com/66219968/135964136-5c8e1223-fa67-4705-8a04-9de7b042086d.png">
    

예를 들어, 주택 가격 예측에서는 입력(x)는 주택에 관한 특성들, 출력으로는 가격을 예측하고자 하는 것!

## **신경망을 이용한 지도 학습**

- 머신러닝의 방법은 지도 학습, 비지도 학습 등 여러 종류가 있음.
- **지도 학습**이란?
    - **정답이 주어져 있는 데이터를 사용**하여 컴퓨터를 학습시키는 방법
    - 신경망을 통해 만들어진 경제적 가치들은 지도학습을 통해 계산됨
    - 지도학습에서는 입력 X와 출력 Y에 매핑되는 함수를 학습하려고 함
    - 신경망을 통한 많은 값들의 생성은 어떤 문제를 해결하기 위한 적절한 X와 Y를 통해 이루어지고, 자율 주행같은 더 큰 시스템에 지도학습 요소들이 적합하게 함.

<img width="500" alt="스크린샷_2021-09-28_오후_6 00 22" src="https://user-images.githubusercontent.com/66219968/135964147-d7c4f7a4-66a0-4749-b7d6-821ea2cadc1c.png">

- 조금씩 다른 신경망들은 **서로 다른 적절한 응용분야**에 적용됨.
    - 부동산 앱 : 표준 신경망 구조 사용
    - 부동산,온라인 광고 : 표준적인 신경망이 사용
    - 이미지 분야 : 주로 CNN 이라고 불리는 **합성곱 신경망** 사용
    - 음성같은 시퀀스 데이터 : 음성은 시간에 흐름에 따라 재생 → 1차원의 시계열 데이터로 나타나는 시퀀스 데이터, 주로 순환 신경망 (RNN) 사용
    - 영어, 중국어같은 언어도 알파벳이나 단어가 쭉 연결 → 시퀀스 데이터로, RNN의 조금 더 복잡한 버전들이 언어 분야에 사용

- **구조적 및 비구조적 데이터를 신경망을 사용하여 예측 가능**
    - 구조적 데이터
        - 데이터베이스로 표현된 데이터
            
            ⇒ 정보의 특성이 잘 정의
            
            - 주택 가격 예측 → 크기, 침실 개수 등
            - 사용자 광고 클릭 여부? → 나이, 광고에 대한 정보
            
    - 비구조적 데이터
        - 이미지, 오디오와 같이 특징적인 값 추출이 어려운 형태의 데이터
        - 딥러닝 덕분에 비구조적 데이터 인식 가능
        
    - 신경망에서 발생하는 경제적인 이익은 구조적 데이터에서 오는 경우가 많음. 정확한 예측을 만들어야하는 경우에 더 잘함.

## **딥러닝의 주요 성장 동력**

- 지난 20년 동안 많은 양의 데이터를 보유하게 됨
    - 전통적인 학습 알고리즘이 효과적으로 처리할 수 있는 양 이상으로

<img width="500" alt="스크린샷_2021-10-01_오후_7 12 02" src="https://user-images.githubusercontent.com/66219968/135964150-0c46fe03-bebd-425b-85c6-c18c80d9740e.png">

⇒ 깊은 모델일 수록 더 많은 데이터 필요, 이는 곧 좋은 퍼포먼스.

 

- **딥러닝의 성능 향상 가능하게 도와준 3가지 요소**
    1. **데이터 양 증가**
    → 많은 데이터를 이용하기 위해 충분히 큰 신경망
    → 데이터의 규모가 딥러닝의 발전을 주도
        
        <img width="500" alt="스크린샷_2021-10-01_오후_7 25 50" src="https://user-images.githubusercontent.com/66219968/135964152-cdbff936-f414-4a22-a3ca-cdee788bb364.png">
        
        - x축은 레이블이 있는 데이터를 의미 
        → 입력값 x와 레이블 y가 같이 있는 훈련세트(m)
        - 훈련할 데이터가 적으면 구현 방법에 따라 성능이 결정되는 경우 많음
        → 알고리즘의 상대적 순위의 정의가 잘 되어있지 않으므로, 특성을 다루는 실력이나 알고리즘의 작은 부분이 성능을 크게 좌우.
        - SVM을 훈련시키는데 여러 특성을 잘 관리한다면 구간 안에 있는 더 큰 신경망보다 SVM이 나을 수 있음.
        - 훈련세트가 아주 클 때, m이 아주 클 때만 큰 신경망이 일관되게 다른 방법을 압도하는 경향을 보임.
    2. **컴퓨터 성능 향상**
    3. **알고리즘의 개선**
    → Sigmoid 함수가 아닌 **ReLU 함수**를 사용함으로 Gradient 소멸 문제 해결
        
        <img width="500" alt="스크린샷_2021-10-01_오후_7 29 50" src="https://user-images.githubusercontent.com/66219968/135964155-e1540f48-1228-4f76-afd6-75e66fd65405.png">
        
        - Sigmoid 함수
            - 함수의 경사가 0에 가까운 곳에서 학습이 굉장히 느림
            - 경사가 0일 때 경사하강법을 사용 → 파라미터가 아주 천천히 바뀌고 학습도 느려짐
        - 신경망의 활성화 함수 → ReUL함수로 바꾸면,
        입력값이 양수인 경우 경사가 1로 모두 같으므로 경사가 서서히 0에 수렴할 가능성이 훨씬 적음.
            
            ⇒ 알고리즘의 혁신으로 계산 능력 크게 향상시킴.
            
- 빠른 계산이 중요한 이유?
    
    <img width="500" alt="스크린샷_2021-10-01_오후_8 23 26" src="https://user-images.githubusercontent.com/66219968/135964158-b01a83b4-9d06-4f71-aef6-bd1e5e5a4bb4.png">
    
    - 아이디어(Idea) 생산 > 코드(Code) 구현 > 실험(Experiment)결과의 시간이 단축
    - 많은 경우 신경망을 학습시키는 과정이 반복적이기 때문 → 생산성 차이

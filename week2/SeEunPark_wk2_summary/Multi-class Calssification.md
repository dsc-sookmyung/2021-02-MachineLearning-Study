# Multi-class Calssification

## Softmax Regression

Softmax : 여러 개의 클래스 분류 시 사용

- ex) Recognizing cats, dogs, and baby chicks
- Softmax 층을 통해 마지막 층 출력값이 주어졌을 때 해당 클래스에 속할 확률을 구할 수 있음.
    - Softmax 층의 활성화 함수는
        - t = e^(z^[L]) 이라는 임시 변수를 사용
        - 모든 값들의 합이 1이 될 수 있도록 모든 임시 변수값들의 합을 나눠서 정규화
        - 정규화를 하기 위해 입력값과 출력값이 모두 벡터

## Training a Softmax Classifier

- 소프트맥스라는 이름은 하드맥스와 반대되는 뜻
    - 하드맥스 : z의 원소를 살펴보고 가장 큰 값이 있는 곳에 1을, 나머지에는 0을 갖는 벡터로 대응
        - 반면, 소프트맥스는 z를 확률들로 대응
        
        ⇒ 소프트맥스 회귀나 활성화 함수는 두 클래스만 다루는 로지스틱 회귀를 일반화
        
    
- 소프트맥스 출력층을 이용해 신경망을 학습하는 법
    - 손실함수
        - 학습 알고리즘이 경사하강법을 이용해서 이 손실 함수의 값을 작게 만드려고 하니 
        결국 -logy^_2 값을 작게 만드는 것
        - 결국 y^_2의 값을 가능한 한 크게 만들어야 함. → 이 값들이 확률이므로 1보다 커질 수 없음.
            
            ⇒ 훈련 세트에서 관측에 따른 클래스가 뭐든 간에 그 클래스에 대한 확률을 가능한 한 크게 만드는 것
            
    - 비용함수 J
        - 매개변수를 설정할 때 전체 훈련 세트에서 학습 알고리즘의 예측에 대한 훈련 샘플의 손실 함수를 합하는 것 → 이를 최소로 하기 위해 경사하강법 사용

- Softmax 와 손실함수를 결합한 역전파의 값
    - dz^[L] = *y*^−*y*
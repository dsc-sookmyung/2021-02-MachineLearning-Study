# Setting up you ML application

## Applied ML is a highly iterative process

- 신경망을 훈련시킬 때는 많은 결정을 내려야함.
    - 신경망이 몇 개의 층을 가지는지
    - 각각의 층이 몇 개의 은닉 유닛을 가지는지
    - 학습률은 무엇인지
    - 서로 다른 층에 사용하는 활성화 함수는 무엇인지
    
    ⇒ 좋은 하이퍼 파라미터 값을 찾기 위해 사이클을 여러번 반복하며 최적의 값을 선택함.
    
    ⇒ 이때 훈련, 개발, 테스트 세트를 잘 설정해 과정을 효율적으로 만들 수 있음.
    

## Train/dev/test sets

- 머신러닝 이전의 시대에는
    - 70 훈련 / 30 테스트 세트로 나누는 것이 일반적
    - 60 테스트 / 20 개발 / 20 테스트 세트로 나눔

- 총 100만 개 이상의 샘플이 있는 현대 빅데이터 시대에는
    - 개발세트와 테스트 세트가 훨씬 더 작은 비율이 되는게 트렌드
    - 개발 세트와 테스트 세트의 목표 : 서로 다른 알고리즘을 확인, 어떤 알고리즘이 더 잘 작동하는지 확인하는 것
        - 개발세트는 평가할 수 있을 정도로만 크면 됨
        - 테스트 세트는 최종 분류기가 어느 정도 성능인지 신뢰 있는 추정치를 제공하는 것이므로 
        백만개가 있으면 만개만 해도 괜찮음
            - 98 훈련 / 1 개발 / 1 테스트
            - 백만개보다 더 많은 샘플을 가지는 경우 99.5 / 0.25 / 0.25 등으로 설정할 수 있음

- 머신러닝문제를 설정할 때는 훈련, 개발, 테스트 세트를 설정하게 되는데
    - 이는 반복을 더 빠르게 함 → 알고리즘의 편향과 분산을 효율적으로 측정
    - 상대적으로 적은 데이터 세트인 경우, 전통적인 비율로 설정하도 괜찮음.
    - 훨씬 더 큰 경우라면 개발과 테스트 세트를 전체의 20 혹은 10보다 더 작게 설정하는 것도 괜찮은 방법

## Mismatched train/test distribution

- 현대 딥러닝의 또 다른 트렌드는 더 많은 사람이 일치하지 않는 훈련 테스트 분포에서 훈련시킨다는 것
    - 사용자가 모든 사진들을 업로드하는 앱을 만든다고 가정 → 고양이 사진을 찾아서 보여주는 것
        
        훈련 세트 : 인터넷에서 다운 받은 고양이 사진
        
        개발 / 테스트 세트 : 앱을 사용하는 사용자들에 의해 구성된 것
        → 저해상도의 사진, 일상적
        
        ⇒ 두 세트의 데이터 분포는 달라질 수 있음.
        
    - 개발 세트가 테스트 세트와 같은 분포에서 오는 것이 좋음.
        - why? 개발 세트를 사용해 다양한 모델을 평가하고 성능을 개선하기 위해 노력할 것이므로
        - but, 딥러닝 알고리즘은 대량의 훈련 데이터가 필요하기 때문에 웹페이지를 크롤링함.
    
    - 테스트 세트를 갖지 않아도 괜찮음.
        - 테스트 세트의 목표 : 최종 네트워크의 성능에 대한 비편향 추정을 제공하는 것
        - but, 비편향 추정이 필요 없는 경우에 테스트 세트를 갖지 않아도 괜찮음.
        - 개발 세트만 있는 경우,
            - 모든 테스트 세트를 훈련 세트에서 훈련시키고 다른 모델 아키텍트를 시도하고 이것을 개발 세트에서 평가 → 이 과정을 반복해서 좋은 모델 찾음.
            - 개발 세트에 데이터를 맞추기 때문에 성능에 대한 비편향추정을 주지 않음.
            - 그 추정이 필요하지 않다면, 테스트 세트가 없어도 괜찮음.
            - 훈련 세트와 개발 세트만 있는 경우, 개발 세트를 테스트 세트라고 부름.
                - 실제로는 테스트 세트를 교차 검증 세트로 사용하는 것
                - 완벽히 좋은 용어는 아님. 테스트 세트에 과적합하기 때문.

## Bias/Variance

- 편향 - 분산 트레이드오프
    
    <img width="500" src="https://user-images.githubusercontent.com/66219968/136645537-5749ddb7-1ce2-472b-b596-25af5dd7cae4.png">
    

- 훈련 세트와 개발 세트의 관계
    - 이 분석은 인간 수준의 성능이 거의 0% 라는 가정에 근거
    ⇒ 최적의 오차, 베이지안 오차라고 불리는 베이지안 오차가 거의 0%라는 가정
    
    <img width="500" src="https://user-images.githubusercontent.com/66219968/136645538-b2e1d62f-df45-4b4e-9cb7-9d570acdb6e6.png">
    
    - 훈련 세트의 오차를 확인함으로써 최소한 훈련 데이터에서 얼마나 알고리즘이 적합한지에 대한 감을 잡을 수 있음 → 편향 문제가 있는지 확인 가능
    - 훈련 세트에서 개발 세트로 갈 때 오차가 얼마나 커지는지 → 분산 문제가 얼마나 나쁜지 감을 잡을 수 있음.

## Basic RECIPE for ML

- 정규화 : 분산을 줄이는데 매우 유용한 기술
    - 편향을 조금 증가 → 약간의 편향 - 분산 트레이드오프
    - 충분히 큰 네트워크가 있다면 크게 증가하지는 않음.

<img width="500" src="https://user-images.githubusercontent.com/66219968/136645539-2da48f43-ffb4-4ceb-8f79-866f6e4cae08.png">

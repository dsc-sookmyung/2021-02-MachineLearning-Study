# WEEK 2

# 머신러닝 어플리케이션

Idea → Code → Experiment → Idea → Code → Experiment → Idea ...

- 위 사이클 계속해서 돌면서 최적의 선택할 수 있도록 한다.
    
    → 그래서 이 사이클을 "얼마나 효율적으로 돌 수 있는지"가 중요한 관건이다.
    

⇒ 이때, train,dev,test 잘 설정하는 것은 이 사이클 과정(반복)을 효율적으로 만들뿐만 아니라, 알고리즘의 편향과 분산을 더 효율적으로 측정할 수 있게 한다.

### Train,Dev,Test set

: 이 세트들을 어떻게 설정하는지에 따라 좋은 성능 가지는 네트워크를 빠르게 찾는 데 큰 도움을 줄 수 있다.

- 개발 및 테스트 세트의 목표
    
    : 서로 다른 알고리즘 작동시켜 어떤 알고리즘이 더 잘 작동하는지 확인하는 것이 목표이다.
    
    → 따라서, 개발 세트는 평가할 수 있을 정도로만 크면 된다. Ex) 2, 10개 알고리즘...
    
    : 최종 네트워크(우리가 선택한 것)의 성능에 대한 비편향 추정을 제공하는 것이 테스트 세트의 목표이다.
    
    → 따라서, 비편향 추정이 필요하지 않으면, 테스트 세트 없어도 된다.
    

**[시대에 따른 전체 데이터 배분]**

- Previous era  → 상대적으로 적은 데이터 세트일 경우 이 방법 채택하기
    1. training set - 70%, test set - 30%
    2. training set - 60%, dev set - 20%, test set - 20%
- Big data era → 더 큰 데이터를 가지는 경우 이 방법 채택하기
    1. training set - 98%, dev set - 1%, test set - 1%
    
    Ex) 샘플 총 백만개 → 개발 세트와 테스트 세트는 각각 만 개만 해도 충분(1/100 크기)
    
          샘플 백만개 이상 → 훈련 세트 99.5%, 개발 세트 - 0.4%, 테스트 세트 - 0.1%도 가능하다.
    

Data : training set + Hold-out cross validation set(dev(development) set) + test set

1. 훈련 세트에 대해 훈련 알고리즘을 적용시킴
2. 1 과정에서 개발 세프(교차 검증 세트)에 대해 다양한 모델 중 어떤 모델이 가장 좋은 성능을 내는지 확인함
3. 더 발전시키고자 하는 최종 모델이 나오면 테스트 세트에 그 모델 적용시켜 알고리즘의 작동을 체크한다.

---

### 편향(Bias)-분산(Variance)

- 특성 x1, x2과 같은 2차원에서는 데이터터를 나타내고 편향과 분산 시각화할 수 있다.
    
    → 높은 차원의 문제에서는 데이터를 나타내거나 결정 경계를 시각화할 수 없다.
    
    → 높은 차원에서는 어떤 부분은 높은 편향을, 어떤 부분은 높은 분산을 가질 수도 있다.
    
- 편향-분산을 이해하기 위한 중요한 두 가지 숫자: 알고리즘 오차에 관련된 것임
    1. Train set error(훈련 세트 오차)
        
        : 훈련 데이터에서 얼마나 알고리즘이 적합한지 감을 잡을 수 있다. → 편향 문제를 알 수 있다.
        
    2. Dev set error(개발 세트 오차)
    
    ⇒ '개발 세트 오차 - 훈련 세트 오차'가 클수록 분산이 나쁨 → 분산 문제를 알 수 있다.
    
    Ex1) 1번이 1%, 2번이 11%인 예제
    
    → 훈련 세트에서는 매우 잘 분류되었지만, 상대적으로 개발 세트에서는 잘 분류되지 못한 경우이다. 즉, 훈련 세트에 과대적합이 되어서 개발 세트가 있는 교차 검증 세트에서 일반화되지 못한 경우디ㅏ.
    
    ⇒ 알고리즘이 high variance(높은 분산)을 갖는다고 말한다.
    
    Ex2) 1번이 15%, 2번이 16%인 예제
    
    → 사람의 대략 0% 오차 가진다고 가정(사람은 사진 보고 고양이 판단 가능하기 때문)
    
    → 훈련 세트가 꽤 높은 오차를 지닌다는 것은 데이터에 과소적합한 것이다.
    
    ⇒ 알고리즘이 high bias(높은 편향)을 갖는다고 말한다. - 선형 분류기는 높은 편향을 가진다.
    
    - 하지만, Ex1에 비해 Ex2는 합리적인 수준의 개발 세트에서 일반화되고 있다.
        
        ⇒ 개발 세트의 성능이 훈련 세트보다 1%밖에 나쁘지 않기 때문이다.
        
    
    Ex3) 1번이 15%, 3번이 30%
    
    → 훈련 세트에 잘 맞지 않음(=훈련 세트 오차가 큼) ⇒ high bias
    
    → 개발 세트에도 잘 맞지 않음 ⇒ high variance
    
    ⇒ 높은 편향, 높은 분산 모두 갖는다고 말한다.
    
    Ex4) 1번이 0.5%, 2번이 1%
    
    ⇒ low bias, low variance
    
- 위 예제에서 중요한 전제(가정)
    1. 베이지안 최적 오차가 0이라는 것
    
    : 베이지안 최적 오차가 15%이면 예제 3번에 훈련 세트 오차가 15%인 것이 합당해지고 low variance를 가진다고 말하게 됨
    
    Ex) 이미지가 너무 흐려서 인간, 컴퓨터가 알아보지 못할 경우 베이지안 최적 오차가 커진다.
    
    1. 훈련 세트와 개발 세트가 같은 확률 분포에서 왔다.

---

### 머신러닝을 위한 기본 레시피

- 최초의 모델 훈련하고 난 후
    1. 알고리즘이 높은 편향을 가지나요? (훈련 세트, 훈련 데이터의 성능 관찰하기)
    
     2-1. 높은 편향 O : 최소한 편향 문제 해결할 때까지는 아래 3가지 반복 시도해보기
    
    → 더 많은 은닉 층, 은닉 유닛을 갖는 더 큰 네트워크 선택하기: 대부분 도움이 되며 절대 해가 없다.
    
    → 더 오랜 기간 훈련시키기/다른 발전된 최적화 알고리즘 선택하기 : 도움이 안 될 수도 있지만 해는 안 됨
    
    → 더 잘 맞는 신경망/네트워크 아키텍처 찾기 : 작동될 수도 안 될 수도 있음
    
    ⇒ 낮은 편향 찾을 때까지 위 3가지를 계속 시도하고 반복한다.
    
    2-2. 높은 편향 X : 3번으로 넘어가기
    
    1. 알고리즘이 높은 분산을 가지나요? (개발 세트 성능 보기: 괜찮은 훈련 세트 성능에서 괜찮은 개발 세트 성능을 일반화할 수 있는지 확인하기)
    
    3-1. 높은 분산 O
    
    → 더 많은 데이터 구하기 : 못 구하는 경우도 존재함
    
    → 정규화(Regulatioin, 규제) 시도하기 : 과대적합 줄이기 위함
    
    → 더 잘 맞는 신경망/네트워크 아키텍처 찾기 : 작동될 수도 안 될 수도 있음 → 완전히 체계화하기 어려움
    
    ⇒ 낮은 분산 찾을 때까지 위 3가지를 계속 시도하고 반복한다.
    
    3-2. 높은 분산 X : 끝!
    
- 높은 편향이냐, 높은 분산이냐에 따라 시도할 수 있는 방법 다르다는 것!
    
    → Ex) 높은 편향 문제 있는데 더 많은 데이터 구하는 것은 별다른 해결책 되지 못함.
    

⇒ 즉, 어떤 알고리즘 문제를 지니는지 정확히 파악하여(+편향, 분산에 대한 높고 낮음을 체크하여) 문제 해결을 시도해야 한다.

---

### Bias Variance tradeoff

: 우리가 시도하는 많은 것들 → 편향 증가/분산 감소 이거나 편향 감소/분산 증가 현상을 가지고 온다.

⇒ 따라서, 편향과 분산 사이의 균형을 신경써야 한다. 가끔은 둘 중 하나를 선택해야 할 때가 존재한다.

[지도 학습에 딥러닝이 매우 유용한 이유 중 하나]

- 더 큰 네트워크 선택하기 → 분산을 해치지 않고 편향을 감소시킨다.
- 더 많은 데이터 구하기 → 편향을 해치지 않고 분산을 감소시킨다.

⇒ 편향-분산 tradeoff가 훨씬 적다 = 편향과 분산의 균형을 신경쓸 일이 적다.

- 정규화는 분산 감소시키는 데 아주 유용한 기술이다. 단, 편향을 조금 증가시킬 수 있어 약간의 편향-분산 트레이드오프가 존재한다. 충분히 큰 네트워크가 있다면 편향이 그렇게 크게 증가하지 않는다.
- 더 큰 네트워크 선택 및 훈련과 정규화의 주된 비용은 "계산 시간"이다.

---

# 2. 신경망 네트워크의 정규화

### 높은 분산 - 과대적합 문제 → 정규화 시도하기

: 신경망에 정규화를 적용하는 방법 알아보자!

1) 잠깐! 들어가기 전 Q&A

- 더 많은 훈련 데이터를 구하는 것은 비용이 많이 들어간다. → 정규화 가장 먼저 시도하기

2) '로지스틱 회귀 활용해' 정규화 적용하기

- 로지스틱 회귀 = 비용 함수 J를 최소화하는 것
- 로지스틱 회귀에 정규화 추가하기 : 정규화 매개변수 λ 추가하기
    1. **L2 regulation**
    
    → 비용함수 J(w, b) 식에 λ / 2m * ||w||^2_2(=w 제곱의 노름)
    
    - w 제곱의 노름 = j의 1부터 nx까지 (w_j)^2의 값을 더한 것 = w의 전치행렬 * w
    
    → 왜 w만 정규화할까? : w는 꽤 높은 차원의 매개변수 벡터이기 때문이다. 측히, 높은 분산을 가질 때 w는 많은 매개변수를 가진다. 실수인 b에 정규화 적용해도 실질적인 차이가 존재하지 않는다.
    
    → 네트워크 훈련할 때 L2 regulation 많이 사용한다.
    
    1. **L1 regulation**
    
    → 비용함수 J(w, b) 식에 λ / m * i=1~nx∑ (|w|) = λ / 2m * ||w||_1
    
    - L1 노름 = i가 1부터 n_x까지 돌며 |w|의 값을 더한 것
    - m 앞에 2 = 스케일링 상수
    - L1 regulation에서 w는 희소해짐 = w 벡터 안에 0이 많아진다. = 모델 압축 쉬워짐
        
        → 모델을 압축하겠다는 목표가 있지 않고서는 L1 regulation 잘 안 쓴다.
        
- λ : 정규화 매개변수로, 하이퍼파라미터임

3) 신경망에 정규화 추가하기

- L2 정규화 = Frobenius norm(프로베니우스 노름) = 행렬 원소 제곱의 합 → ||w^[l]||^2_F
1. dw^[l] = (from backpop) + λ / m * W^[l]
2. dJ / dw^[l] = dW^[l]
3. W^[l] := W^[l] - α* [(from backpop) + λ / m * w^[l]]
    
               = W^[l] - (α*λ / m) * W^[l] - α * (from backpop)
    
    → 원래 식인  W^[l] - α * (from backpop)에서 - (α*λ / m) * W^[l]이 됨
    
    ⇒ L2 정규화의 또 다른 이름이 "Weight decay(가중치 감쇠)"인 이유이다.
    

---

### 과대적합 문제 해결과 분산 감소에 도움이 되는 정규화

1. λ의 값이 크면 클수록 w는 0에 가까워진다.
    
    → 이것이 신경망에 미치는 효과: 은닉 유닛의 영향을 0에 가깝게 줄임으로써 로지스틱 회귀에 가까운 네트워크를 만든다. 모든 은닉 유닛을 사용하지만, 각각의 영향력이 "작아진" 것이다. 즉, 간단한 네트워크가 됨
    
    ⇒ 간단한 네트워크는 과대적합 문제가 덜 발생한다.
    
2. w가 작으면 z도 상대적으로 작은 값을 가진다.(작은 범위의 값을 가진다.)
    
    → 모든 층은 선형 회귀처럼 거의 직선의 함수 가진다. 매우 복잡한 비선형 함수보다 더 간단한 함수가 존재하고, 이는 과대적합의 가능성을 줄인다.
    
3. 모든 층이 선형이면 전체 네트워크도 선형이다.
    
    → 전체 신경망은 선형 함수로부터 그리 멀지 않은 곳에서 계산이 이루어질 것이다.
    

⇒ 매우 복잡한 결정, 비선형 결정의 경계에 맞추기가 불가능하다.  

**Tip**

- 비용함수 J가 단조감소하는 형태로 구현하고자 할 때
    
    : J 함수에서 첫 항(손실함수의 시그마)만을 그리지 않고 두 번째 항(정규화 적용한 것)도 그렸는지 디버깅할 때 확인하기
    

---

### 또 다른 정규화 기법 - 드롭아웃/역드롭아웃

**드롭아웃(dropout)** → 각각의 샘플에서 더 작은 네트워크를 훈련시키는 방식이다.

1. 신경망의 각각의 층에 대해 노드를 삭제하는 확률을 설정하는 방식이다.
2. 삭제된 노드의 들어가는 링크, 나가는 링크는 모두 삭제한다.
    
    → 더 작은 네트워크가 됨
    
3. 2번의 결과로 나온 네트워크에 대해 하나의 샘플을 역전파로 훈련시킨다.
4. 다른 훈련 샘플에서도 마찬가지로 3번과 같이 진행한다.

**드롭아웃 기법 중 하나 -** **역드롭아웃(inverted dropout)**

예제) 층 3개인 신경망

```python
keep_prob = 0.8 # 주어진 은닉 유닛이 유지될 확률 = 0.8 => 삭제될 확률 = 0.2
# 0.8보다 작을지의 여부 -> 0.8의 확률로 1(true), 0.2의 확률로 0(false)이 됨 -> 0, 1로 구성된 행렬 나옴
d3 = np.random.rand(a2.shape[0], a3.shape[1]) < keep_prob
a3 = np.multiply(a3, d3) # 3번째 층의 활성화 a3: a3에 d3의 요소 곱해줌 a3 *= d3도 가능
a3 /= keep_pro     # 역 드롭아웃이라 불리는 기법 -> 활성화의 기댓값 유지하기 위해 수행한다.
```

- keep_prob의 값을 다시 나눠줌으로써 활성화 값의 기댓값을 같게 유지한다.
- 신경망 테스트 시 역 드롭아웃 기법이 유용하다.
    
    → 스케일링 문제가 적기 때문이다.
    
- 드롭아웃 방법 중 가장 보편적인 것
- 경사 하강법의 한 번 반복마다 서로 다른 은닉 유닛이 0이 된다.

**테스트**: 예측(prediction) → 무작위 결과 선호 X

- 명시적으로 드롭아웃 사용하지 않는다 → 불필요하게 노이즈 증가시키지 않는다.

---

### 드롭아웃의 작동

: 특성 노드에 가해지는 가중치 줄임 = 가중치의 분산

- 각각의 층에 대해 서로 다른 keep_prob 값 지정해도 된다.
    
    Ex1) 과대적합의 문제 발생할 확률 거의 0인 층에 대해서는 keep_prob가 1.0인 것 → 드롭아웃 적용 X
    
    Ex2) 과대적합 문제 발생할 확률 높은 층에 대해서는 작은 값을 가지는 keep_prob 설정하기
    
- 입력 층에 대해서도 드롭아웃 적용할 수 있다. 하지만, 대부분은 0.9나 1.0 사용한다 → 입력 특성의 대부분을 삭제하는 것은 좋지 않기 때문 ⇒ 입력 층에 드롭아웃 적용할 경우 1.0에 가까운 값 활용하기
- 단점1: 교차 검증 → 더 많은 하이퍼파라미터 필요함
- 단점2: 비용함수 J가 더 이상 잘 정의되지 않는다. → 디버깅하기 어려워짐
    
    ⇒ keep_prob 값을 1로 맞추고 J가 단조감소하는지 확인 후, 다시 드롭아웃 적용하기
    

---

### 다른 정규화 방법들 - 데이터증식 및 조기종료

**데이터증식(Data augmentation)**

- 이미지 변형, 대칭, 확대 등을 활용해서 훈련 샘플 추가하기 → 새로운 훈련 샘플 추가하는 것보다는 정보 수집에 있어서 효과가 적지만, 컴퓨터적인 추가 비용이 들지 않고 할 수 있다는 장점이 존재한다.

**조기종료(Early Stoping)**

- 경사하강법 1번 실행해서 작은 w, 중간 w, 큰 w의 값을 얻는다.
- 단점 : 비용함수 J 최적화하는 것과 과대적합 막는 것은 본래 독립적 = 별개의 것 → 문제 둘을 섞어버림 : 경사하강법 중간에 멈춤 > 비용함수 J 최적화하는 것 잘 안됨
    
    ⇒ 대안: L2 정규화 사용하기 ⇒ 더 오랜 시간 훈련 가능(이 방법의 경우 정규화 매개변수에 많은 값 시도해야 하는 단점도 존재함)
    

---

### 로지스틱 회귀의 일반화 - 소프트맥스 회귀

- 클래스 분류 시 사용된다.
- 마지막 층의 출력값이 주이면 각각의 클래스가 일어날 확률을 구할 수 있다.
    
    과정
    
1. Z^[L]의 지수화 → T = e^z: 똑같은 벡터 크기 가짐
2. 모든 요소의 합이 1이 될 수 있도록 T^[i]의 값을 t 행렬 전체 합으로 나눈다.
    
    학습
    
- 손실함수 L 활용 → L(y^, y) = - ∑ y_i * (log y_i)
    
    ⇒ 손실함수를 활용한 학습 → log y_i의 값을 최대한 큰 값을 가지도록 한다.
    
- 역전파 → dz^[L] = ^y - y

---

# 4-1. 합성곱 신경망

### 컴퓨터 비전(Computer vision)

- 자연어 처리, 예술, 얼굴인식, 자율주행 자동차 등 다양한 분야에 응용된다.
- 주로 다루는 분야
    1. 이미지분류
    2. 객체인식
    3. 신경망 스타일 변형

Ex) 자율주행 자동차가 다른 자동차와 그 위치를 인식할 수 있도록, 휴대폰의 얼굴 인식을 더 선명하게 할 수 있도록 도와준다.

→ 컴퓨터 비전에서는 "입력데이터가 아주 크다" ⇒ 합성곱 신경망의 구현이 필요함

---

### 모서리 감지 예시

1. 이미지에서 수직인 모서리를 찾는다.
2. 이미지에서 수평인 모서리를 찾는다.

→ 수직인 모서리 감지하는 방법

- filter(kernel) 만들기 (3*3 행렬) → [ [1, 0, -1], [1, 0, -1], [1, 0, -1] ]
    
    → 왼쪽은 밝은 부분, 오른쪽은 어두운 부분이다.
    
    → [10, 10, 10, 0, 0, 0] 행렬이 열로 6개, 즉, 6 * 6 행렬이 있다고 할 때, 합성곱 적용하면 밝은 부분이 중앙이 됨 = 원래 이미지(6*6 행렬)의 경계선을 가리킨다.
    

→ 수평인 모서리 감지하는 방법

- 똑같이 커널/필터 활용한다. 단, 수직 기준 90˚ 돌려서 [ [1, 1, 1], [0, 0, 0], [-1, -1, -1] ] 행렬 활용하기

---

- Python, 그리고 컴퓨터 비전을 제공하는 모든 딥러닝 프레임워크는 합성곱을 하는 함수가 구현되어 있다
    - Pyhon → ConvForward 함수
    - tensorflow → tf.nn.conv2d
    - Keras → Conv2d

---

### 윤곽선 차이 - 서로 다른 밝기의 전환(양과 음의 전환)

[ 세로 윤곽선 기준 행렬 ] ⇒ 90˚ 회전하면 가로 윤곽선 검출하는 행렬 됨

1. Sobel filter
    
    : [ [1, 2, 1], [0, 0, 0], [-1, -2, -1] ]
    
    → 장점 : 중간 부분의 픽셀에 더 중점을 둠 ⇒ 더 선명히 보일 수 있다.
    
2. Scharr filter
    
    : [ [-3, 10, -3], [0, 0, 0], [-3, 10, -3] ]
    
- 위에서 본 필터 행렬들 각각을 변수로 설정하기 → 총 9가지 변수 생성됨
- 역전파로 이 변수들 학습시켜 원하는 필터로 학습하고 제일 좋은 필터 고르면 됨
- 즉, 변수 말고 상수로 구현하는 사람이 직접 지정하는 것보다 변수로 활용하면 문제에 더 적합한 필터 고를 수 있음
- 이런 방법으로 75도, 50도 등 다양한 각도로 회전해 윤곽선 검출이 가능함

---

### 패딩

: 합성곱 수행 시 발생하는 2가지 문제를 해결하기 위해 합성곱 연산 전 이미지를 덧대는 것을 의미함

[ **합성곱 연산 단점** ]

1. 한 번의 합성곱 연산 수행할 때마다 이미지 크기가 줄어든다.
2. 모서리 부분은 이미지 중앙 부분보다 훨씬 적게 사용된다.

Ex) 6*6 크기의 이미지를 *8 * 8 이미지가 될 수 있도록 경계를 덧댄다. ⇒ 한 번의 합성곱 연산을 수행해도 이미지가 본래 크기인 6 * 6을 유지할 수 있다.*

→ 이 경우에는 padding(p) = 1이다.

- p = 가장자리에 추가한 픽셀
- 패딩을 함으로써 가장자리의 정보를 덜 가져오는 일을 줄일 수 있다.
- 패딩의 크기는 원하는 만큼 하면 된다.
1. 유효 합성곱(Valid convolution)

: no padding

- n x n * f x f → n - f + 1 x n - f + 1
1. 동일 합성곱(Same convolution)

: pad so that output size is the same as the input size

- n x n → n + 2p x n + 2p ⇒ n + 2p x n + 2p *  f x f → n + 2p - f + 1 x n + 2p - f + 1
    
    → 여기서 n + 2p - f + 1 = n이 되는 것이 동일 합성곱이다.
    
    - n + 2p - f + 1 = n ⇒ 2p + 1 = f ⇒ p = (f - 1) / 2

Ex) 6 x 6 input size에 p = 2 만큼의 패딩을 한 8 x 8 크기에 3 x 3 필터로 합성곱 연산 수행하면 본래 input size인 6 x 6 크기의 output size 나옴

[ 컴퓨터 비전에서의 필터 f * f]

- 대부분 홀수임
    1. f가 홀수이어야 대칭적인 패딩 넣을 수 있다.
    2. f가 홀수이면 이미지에서 중심 위치/중심 픽셀이 존재한다.

---

### 합성곱 신경망의 기본 구성 요소 - 스트라이드 합성곱

: 본래 합성곱 기본은 한 칸 씩 이동해서 필터크기에 대해 계산 진행하지만, 스트라이드 s가 주어지면 그것에 맞게 건너뛰기하는 방식이다. 

padding → p, stride → s

- n x n → n + 2p → n + 2p - f → (n + 2p - f) / s → (n + 2p - f) / s + 1
    
    ⇒  (n + 2p - f) / s + 1 x (n + 2p - f) / s + 1 
    
- (n + 2p - f) / s가 정수가 아닐 때 → "내림"하기
- 보통은 패딩을 해서 필터 크기 f * f에 딱 맞도록 조정해주고 stride를 해서 정수가 되게 한다.

---

### 입체형 이미지 합성곱

- RGB 색 채널에 따라 채널(깊이) x 3이 추가된다.
    
    → 이에 따라 필터도 f x f x 3이 된다. 이때 결과 output size는 x 3이 되지 않고, 필터를 몇 종류 사용하느냐에 따라 x 가 수행된다.
    
- 수학의 다른 분야, 신호 처리 분야에서는 본래 합성곱은 "미러링"이 이루어진 후, 현재 우리가 배운 것이 적용된다.
    
    → 하지만, 딥러닝 분야에서는 미러링의 효과인 결합법칙을 활용할 때가 거의 없다 → 따라서 미러링 하지 않고 그냥 합성곱 진행한다. 그래서 원래는 교차상관이라고 불리는데, 딥러닝 분야에서는 합성곱이라고 관습적으로 부르는 것이다.
    

---

### 합성곱 네트워크

[ 용어 정리 ]

1. l: l번째 계층
2. f^[l]: 필터의 크기
3. p^[l]: 패딩의 양
4. s^[l]: 스트라이드의 크기
5. n_H: 이미지의 높이
6. n_W: 이미지의 넓이
7. n_c: 채널의 수

[ 한 계층 ]

: 합성곱 연산 → 편향 추가(b | b는 실수) → 비선형 활성화 함수(ex) ReLU)

[ 전체 ]

- 대부분의 합성곱 연산으로 구성된 네트워크를 보면, 합성곱 신경망의 크기는 깊어질수록 점점 줄어든다.

---

### 층의 또 다른 유형 - 풀링과 FC

풀링 - 최대 풀링과 평균 풀링

- 최대 풀링은 필터 f x f 크기만큼에 해당하는 input size에서 최댓값을 구해 output에 출력한다.
- 평균 풀링은 그 크기에 포함된 모든 원소를 더해 평균을 내고, 그것을 output으로 한다.
- 하이퍼파라미터 f와 s는 f = 2,  s = 2이다.
- 높이와 넓이를 2분의 1로 줄어들게 한다
- 역전파를 적용할 수 있는 변수가 없다 → 직접, 혹은 교차 검증을 통해 "정해진" 하이퍼파라미터이기 때문

---

### CNN, 그리고 합성곱의 필요성

- 합성곱 신경망에는 두 가지 관습이 존재한다.
    1. Conv1과 Pool1을 같은 층으로 보는 경우 → 풀링 층은 학습 가능한 변수가 존재하지 않기 때문에 Conv1과 하나의 층으로 본다.
    2. Conv1과 Pool1을 개별 층으로 보는 경우
    
    → 이 수업에서는 1 관습을 따른다.
    
- 위에서 언급했듯이, 보통 합성곱 신경망은 Conv1 → Pool1 → Conv2 → Pool2 → Flatten → FC → FC → Softmax 순으로 진행된다. 이 구조는 "고전적인 신경망"인 LeNet-5와 굉장히 유사하다.
- 합성곱을 사용하면 변수를 적게 사용할 수 있다.
    1. "변수 공유" → 한 부분의 이미지의 특성을 검출하는 필터가 input의 다른 부분에서 똑같이 적용된다.
    2. "최소 연결" → output의 이미지의 일부에 영향을 받고 나머지 픽셀들의 영향을 받지 않는다.
        
        ⇒ 과대적합의 가능성이 낮아진다.
        
- 합성곱을 사용하면 이동 불변성을 포착하는 것에도 좋다. → 이동 불변성 ? = 이미지에 어떤 조금의 변화가 있어도 이미지를 포착할 수 있다.

⇒ 이러한 이유 때문에 합성곱이 필요한, 유용한 것이다.